{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-11-07 12:16:10.283143: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-07 12:16:10.317239: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-07 12:16:10.317658: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-07 12:16:11.099027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources get initialised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at SpanBERT/spanbert-large-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "#from labeling_functions import get_all_lfs\n",
    "from pruning_lfs import prune_lfs\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/pruning_lfs.py:52: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  merged_data.append([index, polarity, cov_simp, cov_src, precision, 1 - precision, cov_simp+cov_src, abs(cov_simp - cov_src), abs(cov_simp - cov_src)/(cov_simp+cov_src)])\n"
     ]
    }
   ],
   "source": [
    "all_lfs = prune_lfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"workspace/datasets/final_combined_with_index.pkl\", 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "SIMPLE = 0\n",
    "NOT_SIMPLE = 1\n",
    "LOST_MEANING = 2\n",
    "\n",
    "label_map = {-1: \"ABSTAIN\", 0: \"SIMPLE\", 1: \"NOT_SIMPLE\", 2: \"LOST_MEANING\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_type = \"simp\"\n",
    "#current_type = \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['simplified_snt'] = dataset[current_type]\n",
    "dataset['source_snt'] = dataset['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = \"MTurkSF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['ds_id'] == selected_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Target_Audience</th>\n",
       "      <th>Domain</th>\n",
       "      <th>index</th>\n",
       "      <th>src</th>\n",
       "      <th>src_id</th>\n",
       "      <th>simp</th>\n",
       "      <th>simp_id</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>duplicated</th>\n",
       "      <th>topic</th>\n",
       "      <th>src_title</th>\n",
       "      <th>simp_title</th>\n",
       "      <th>similarity</th>\n",
       "      <th>topics</th>\n",
       "      <th>val_split</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>simplified_snt</th>\n",
       "      <th>source_snt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506530</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__0__0</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>abdominalwalldefect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506531</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__0__1</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>abdominalwalldefect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.968228</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506532</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__0__2</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>abdominalwalldefect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.954932</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506533</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__0__3</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>abdominalwalldefect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.923728</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506534</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__0__4</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>abdominalwalldefect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.956304</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "      <td>Abdominal wall defects are a type of congenita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506746</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__62__216</td>\n",
       "      <td>Visual impairment may cause difficulties with ...</td>\n",
       "      <td>62</td>\n",
       "      <td>Visual impairment may cause difficult with nor...</td>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>visual-impairment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.909561</td>\n",
       "      <td>Visual impairment may cause difficult with nor...</td>\n",
       "      <td>Visual impairment may cause difficulties with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506747</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__62__217</td>\n",
       "      <td>Visual impairment may cause difficulties with ...</td>\n",
       "      <td>62</td>\n",
       "      <td>Visual impairment may cause trouble with norma...</td>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>visual-impairment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982249</td>\n",
       "      <td>Visual impairment may cause trouble with norma...</td>\n",
       "      <td>Visual impairment may cause difficulties with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506748</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__60__218</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>60</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>visual-impairment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506749</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__60__219</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>60</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>visual-impairment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.964666</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506750</th>\n",
       "      <td>MTurkSF</td>\n",
       "      <td>2022</td>\n",
       "      <td>non-experts</td>\n",
       "      <td>medical</td>\n",
       "      <td>MTurkSF__60__220</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>60</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>visual-impairment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.928627</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "      <td>Visual impairment, also known as vision impair...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds_id  Year Target_Audience   Domain             index  \\\n",
       "506530  MTurkSF  2022     non-experts  medical     MTurkSF__0__0   \n",
       "506531  MTurkSF  2022     non-experts  medical     MTurkSF__0__1   \n",
       "506532  MTurkSF  2022     non-experts  medical     MTurkSF__0__2   \n",
       "506533  MTurkSF  2022     non-experts  medical     MTurkSF__0__3   \n",
       "506534  MTurkSF  2022     non-experts  medical     MTurkSF__0__4   \n",
       "...         ...   ...             ...      ...               ...   \n",
       "506746  MTurkSF  2022     non-experts  medical  MTurkSF__62__216   \n",
       "506747  MTurkSF  2022     non-experts  medical  MTurkSF__62__217   \n",
       "506748  MTurkSF  2022     non-experts  medical  MTurkSF__60__218   \n",
       "506749  MTurkSF  2022     non-experts  medical  MTurkSF__60__219   \n",
       "506750  MTurkSF  2022     non-experts  medical  MTurkSF__60__220   \n",
       "\n",
       "                                                      src  src_id  \\\n",
       "506530  Abdominal wall defects are a type of congenita...       0   \n",
       "506531  Abdominal wall defects are a type of congenita...       0   \n",
       "506532  Abdominal wall defects are a type of congenita...       0   \n",
       "506533  Abdominal wall defects are a type of congenita...       0   \n",
       "506534  Abdominal wall defects are a type of congenita...       0   \n",
       "...                                                   ...     ...   \n",
       "506746  Visual impairment may cause difficulties with ...      62   \n",
       "506747  Visual impairment may cause difficulties with ...      62   \n",
       "506748  Visual impairment, also known as vision impair...      60   \n",
       "506749  Visual impairment, also known as vision impair...      60   \n",
       "506750  Visual impairment, also known as vision impair...      60   \n",
       "\n",
       "                                                     simp  simp_id label  ...  \\\n",
       "506530  Abdominal wall defects are a type of congenita...        0   NaN  ...   \n",
       "506531  Abdominal wall defects are a type of congenita...        1   NaN  ...   \n",
       "506532  Abdominal wall defects are a type of congenita...        2   NaN  ...   \n",
       "506533  Abdominal wall defects are a type of congenita...        3   NaN  ...   \n",
       "506534  Abdominal wall defects are a type of congenita...        4   NaN  ...   \n",
       "...                                                   ...      ...   ...  ...   \n",
       "506746  Visual impairment may cause difficult with nor...      216   NaN  ...   \n",
       "506747  Visual impairment may cause trouble with norma...      217   NaN  ...   \n",
       "506748  Visual impairment, also known as vision impair...      218   NaN  ...   \n",
       "506749  Visual impairment, also known as vision impair...      219   NaN  ...   \n",
       "506750  Visual impairment, also known as vision impair...      220   NaN  ...   \n",
       "\n",
       "       duplicated                topic  src_title simp_title similarity  \\\n",
       "506530      False  abdominalwalldefect        NaN        NaN        NaN   \n",
       "506531      False  abdominalwalldefect        NaN        NaN        NaN   \n",
       "506532      False  abdominalwalldefect        NaN        NaN        NaN   \n",
       "506533      False  abdominalwalldefect        NaN        NaN        NaN   \n",
       "506534      False  abdominalwalldefect        NaN        NaN        NaN   \n",
       "...           ...                  ...        ...        ...        ...   \n",
       "506746      False    visual-impairment        NaN        NaN        NaN   \n",
       "506747      False    visual-impairment        NaN        NaN        NaN   \n",
       "506748      False    visual-impairment        NaN        NaN        NaN   \n",
       "506749      False    visual-impairment        NaN        NaN        NaN   \n",
       "506750      False    visual-impairment        NaN        NaN        NaN   \n",
       "\n",
       "       topics  val_split bert_score  \\\n",
       "506530    NaN      False   0.953776   \n",
       "506531    NaN      False   0.968228   \n",
       "506532    NaN      False   0.954932   \n",
       "506533    NaN      False   0.923728   \n",
       "506534    NaN      False   0.956304   \n",
       "...       ...        ...        ...   \n",
       "506746    NaN      False   0.909561   \n",
       "506747    NaN      False   0.982249   \n",
       "506748    NaN      False   0.984148   \n",
       "506749    NaN      False   0.964666   \n",
       "506750    NaN      False   0.928627   \n",
       "\n",
       "                                           simplified_snt  \\\n",
       "506530  Abdominal wall defects are a type of congenita...   \n",
       "506531  Abdominal wall defects are a type of congenita...   \n",
       "506532  Abdominal wall defects are a type of congenita...   \n",
       "506533  Abdominal wall defects are a type of congenita...   \n",
       "506534  Abdominal wall defects are a type of congenita...   \n",
       "...                                                   ...   \n",
       "506746  Visual impairment may cause difficult with nor...   \n",
       "506747  Visual impairment may cause trouble with norma...   \n",
       "506748  Visual impairment, also known as vision impair...   \n",
       "506749  Visual impairment, also known as vision impair...   \n",
       "506750  Visual impairment, also known as vision impair...   \n",
       "\n",
       "                                               source_snt  \n",
       "506530  Abdominal wall defects are a type of congenita...  \n",
       "506531  Abdominal wall defects are a type of congenita...  \n",
       "506532  Abdominal wall defects are a type of congenita...  \n",
       "506533  Abdominal wall defects are a type of congenita...  \n",
       "506534  Abdominal wall defects are a type of congenita...  \n",
       "...                                                   ...  \n",
       "506746  Visual impairment may cause difficulties with ...  \n",
       "506747  Visual impairment may cause difficulties with ...  \n",
       "506748  Visual impairment, also known as vision impair...  \n",
       "506749  Visual impairment, also known as vision impair...  \n",
       "506750  Visual impairment, also known as vision impair...  \n",
       "\n",
       "[221 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = f\"/workspace/datasets/{selected_dataset}labels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(label_path):\n",
    "    os.mkdir(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finished_batches(path = f\"/workspace/datasets/{selected_dataset}labels/*\"):\n",
    "    label_paths = glob.glob(path)\n",
    "    fin_batches = [int(path.split(\"_\")[-1]) for path in label_paths if \"labels_\" in path]\n",
    "    return set(fin_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_used_lfs(all_lfs, path = f\"/workspace/datasets/{selected_dataset}labels/used_lfs.pkl\"):\n",
    "    names = [lf.name for lf in all_lfs]\n",
    "    pickle.dump(names, open(path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bc14d9e6d44f98977460983dc45077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 0/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 20/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 40/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 60/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 80/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 100/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 120/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 140/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:29<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 160/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 180/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 200/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished on 220/221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "start = 0\n",
    "\n",
    "save_used_lfs(all_lfs)\n",
    "\n",
    "for i in tqdm(range(start, len(dataset), batch_size), position=1):\n",
    "    if not i in get_finished_batches():\n",
    "        try:\n",
    "            applier = PandasLFApplier(all_lfs)\n",
    "            labels = applier.apply(dataset[i:i+batch_size], progress_bar=True)\n",
    "            \n",
    "            pickle.dump(labels, open(f\"/workspace/datasets/{selected_dataset}labels/labels_{current_type}_{i}\", \"wb\"))\n",
    "            print(f\"finished on {i}/{len(dataset)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"something went wrong with batch {i}\")\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build ds labels\n",
    "ds_label_path = f\"/workspace/datasets/ds_labels\"\n",
    "if not os.path.isdir(ds_label_path):\n",
    "    os.mkdir(ds_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_labels(ds=\"MTurkSF\"):\n",
    "    simp_paths = sorted(glob.glob(f\"workspace/datasets/{ds}labels/labels_simp*\"), key=lambda x: int(x.split(\"_\")[-1]))\n",
    "    src_paths = sorted(glob.glob(f\"workspace/datasets/{ds}labels/labels_src*\"), key=lambda x: int(x.split(\"_\")[-1]))\n",
    "\n",
    "    simp_labels = [pickle.load(open(path, \"rb\")) for path in simp_paths]\n",
    "    src_labels = [pickle.load(open(path, \"rb\")) for path in src_paths]\n",
    "\n",
    "    simp_labels = np.concatenate(simp_labels)\n",
    "    src_labels = np.concatenate(src_labels)\n",
    "\n",
    "    pickle.dump(simp_labels, open(f\"{ds_label_path}/{ds}_simp_labels.pkl\", \"wb\"))\n",
    "    pickle.dump(src_labels, open(f\"{ds_label_path}/{ds}_src_labels.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MTurkSF'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_labels(selected_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
