{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(only_few_dims):\n",
    "    data_merged = []\n",
    "    labels = []\n",
    "\n",
    "    for d_s in ['MTurkSF', 'Wiki-Manual']: #,  'britannica', 'ASSET', 'eval'\n",
    "        simp_path = f\"/workspace/datasets/ds_labels/{d_s}_simp_labels.pkl\"        \n",
    "        src_path = f\"/workspace/datasets/ds_labels/{d_s}_src_labels.pkl\"  \n",
    "\n",
    "        simp_labels = pickle.load(open(simp_path, \"rb\"))\n",
    "        src_labels = pickle.load(open(src_path, \"rb\")) \n",
    "\n",
    "        print(len(simp_labels[0]))\n",
    "        print(len(src_labels[0]))\n",
    "\n",
    "        for entry in simp_labels:\n",
    "            data_merged.append(entry.tolist())\n",
    "\n",
    "        for entry in src_labels:\n",
    "            data_merged.append(entry.tolist())\n",
    "\n",
    "        curr_lab = [0] * len(simp_labels) + [1] * len(simp_labels)\n",
    "        labels = labels + curr_lab\n",
    "\n",
    "    if only_few_dims > 0:\n",
    "        dims_to_include = []\n",
    "        \n",
    "        # only include dimensions where values are the most different \n",
    "        for lf_dim in range(len(simp_labels[0])):\n",
    "            sum_i_src = 0\n",
    "            sum_i_simp = 0\n",
    "            for d_p in range(len(data_merged)):\n",
    "                if labels[d_p] == 0:\n",
    "                    sum_i_simp += data_merged[d_p][lf_dim]\n",
    "                else:\n",
    "                    sum_i_src += data_merged[d_p][lf_dim]\n",
    "\n",
    "            dist = abs(sum_i_simp - sum_i_src)\n",
    "\n",
    "            if len(dims_to_include) < only_few_dims:\n",
    "                dims_to_include.append((lf_dim, dist))\n",
    "            else:\n",
    "                replace_cand_dist = -1\n",
    "                replace_cand_dim = -1\n",
    "                # find dim with lowest dist\n",
    "                for inc_dim in range(len(dims_to_include)):\n",
    "                    if dims_to_include[inc_dim][1] < dist and (replace_cand_dist == -1 or replace_cand_dist > dims_to_include[inc_dim][1]):\n",
    "                        replace_cand_dim = inc_dim\n",
    "                        replace_cand_dist = dims_to_include[inc_dim][1]\n",
    "                            \n",
    "                # replace it\n",
    "                if replace_cand_dim > -1:\n",
    "                    dims_to_include[replace_cand_dim] = (lf_dim, dist)\n",
    "\n",
    "        new_data = []\n",
    "        for d_p in range(len(data_merged)):\n",
    "            new_dp = []\n",
    "            for inc_dims in dims_to_include:\n",
    "                new_dp.append(data_merged[d_p][inc_dims[0]])\n",
    "            new_data.append(new_dp)\n",
    "\n",
    "        data_merged = new_data                    \n",
    "\n",
    "    print('----')\n",
    "    print(len(data_merged))\n",
    "    print(len(labels))\n",
    "    X, y = shuffle(data_merged, labels, random_state=42)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "328\n",
      "328\n",
      "328\n",
      "----\n",
      "2550\n",
      "2550\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, random_state=42)\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "clfs = {'gb': clf_gb, 'rf': clf_rf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb\n",
      "0.5305882352941176\n",
      "[0.5372549  0.51764706 0.55686275 0.54509804 0.54509804 0.55686275\n",
      " 0.49411765 0.50588235 0.5372549  0.50980392]\n",
      "___\n",
      "rf\n",
      "0.512156862745098\n",
      "[0.50980392 0.51372549 0.51372549 0.51372549 0.53333333 0.52941176\n",
      " 0.49019608 0.49803922 0.51372549 0.50588235]\n",
      "___\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for clf in clfs:\n",
    "    cv_scores = cross_val_score(clfs[clf], X, y, cv=kfold)\n",
    "    print(clf)\n",
    "    print(sum(cv_scores)/len(cv_scores))\n",
    "    print(cv_scores)\n",
    "    print('___')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gb = GradientBoostingRegressor(random_state=42)\n",
    "reg_rf = RandomForestRegressor(random_state=42)\n",
    "reg_mlp = MLPRegressor(random_state=42)\n",
    "\n",
    "regs = {'reg_gb': reg_gb, 'reg_rf': reg_rf, 'reg_mlp': reg_mlp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_gb\n",
      "-0.010864870567175755\n",
      "[-0.01472845 -0.01104293  0.01193676 -0.00582593 -0.02000232 -0.00553896\n",
      " -0.03742129 -0.00481826  0.00069379 -0.02190112]\n",
      "___\n",
      "reg_rf\n",
      "-0.04595905274739347\n",
      "[-0.03338488 -0.03315407 -0.04928691 -0.04124212 -0.0269516  -0.0342978\n",
      " -0.0618418  -0.04096703 -0.06016164 -0.07830269]\n",
      "___\n",
      "reg_mlp\n",
      "-0.019197059935635453\n",
      "[-0.01190631 -0.05047223 -0.00388514 -0.00312347 -0.01972183 -0.00899656\n",
      " -0.03781366 -0.01562139 -0.0057205  -0.0347095 ]\n",
      "___\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for reg in regs:\n",
    "    cv_scores = cross_val_score(regs[reg], X, y, cv=kfold)\n",
    "    print(reg)\n",
    "    print(sum(cv_scores)/len(cv_scores))\n",
    "    print(cv_scores)\n",
    "    print('___')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
