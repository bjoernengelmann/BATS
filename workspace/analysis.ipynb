{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from labeling_functions import get_all_lfs\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "all_lfs = get_all_lfs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_simp = pickle.load(open(\"/workspace/datasets/eval_simp_labels.pkl\", \"rb\"))\n",
    "labels_src = pickle.load(open(\"/workspace/datasets/eval_src_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "lfa_simp = LFAnalysis(L=labels_simp, lfs=all_lfs).lf_summary()\n",
    "lfa_src = LFAnalysis(L=labels_src, lfs=all_lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfa_simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfa_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(lfa_simp).to_excel(\"/workspace/datasets/labels_simp.xlsx\")  \n",
    "pd.DataFrame(lfa_src).to_excel(\"/workspace/datasets/labels_src.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simp = pd.DataFrame(lfa_simp)\n",
    "df_src = pd.DataFrame(lfa_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = []\n",
    "\n",
    "for index, row in df_simp.iterrows():\n",
    "    polarity = -1\n",
    "    cov_simp = row['Coverage']\n",
    "    cov_src = df_src.loc[index]['Coverage']\n",
    "\n",
    "    if len(row['Polarity']) > 0:\n",
    "        polarity = row['Polarity'][0]\n",
    "    else:\n",
    "        if len(df_src.loc[index]['Polarity']) > 0:\n",
    "            polarity = df_src.loc[index]['Polarity'][0]\n",
    "\n",
    "    if polarity == -1:\n",
    "        continue\n",
    "\n",
    "    precision = -1\n",
    "\n",
    "    if polarity == 0:\n",
    "        precision = cov_simp/(cov_simp + cov_src)\n",
    "    else:\n",
    "        precision = cov_src/(cov_simp + cov_src)\n",
    "\n",
    "    merged_data.append([index, polarity, cov_simp, cov_src, precision, 1 - precision, cov_simp+cov_src, abs(cov_simp - cov_src), abs(cov_simp - cov_src)/(cov_simp+cov_src)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_md = pd.DataFrame(merged_data)\n",
    "df_md.columns = ['name', 'polarity', 'cov_simp', 'cov_src', 'precision', 'inv_precision', 'total_coverage', 'distance', 'norm_dist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep/throw decisions for LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = []\n",
    "\n",
    "for index, row in df_md.iterrows():\n",
    "    if row['precision'] > 0:\n",
    "        if row['total_coverage'] >= 0.05:\n",
    "            if row['precision'] >= 0.7:\n",
    "                decision.append('JA')\n",
    "            else: \n",
    "                if row['precision'] >= 0.5 and row['norm_dist'] >= 0.05:\n",
    "                    decision.append('JA')\n",
    "                else:\n",
    "                    if row['precision'] <= 0.3 and row['distance'] >= 0.01:\n",
    "                        decision.append('INVERSE')\n",
    "                    else:\n",
    "                        decision.append('NEIN')\n",
    "        else:\n",
    "            if row['precision'] > 0.5 and row['distance'] >= 0.005 and row['total_coverage'] >= 0.02:\n",
    "                decision.append('JA')\n",
    "            else:\n",
    "                decision.append('NEIN')\n",
    "    else:\n",
    "        decision.append('NEIN')\n",
    "\n",
    "df_md['decision'] = decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information, which LFs could require more thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_names_similar(a, b):\n",
    "    if a['polarity'] != b['polarity']:\n",
    "        return False\n",
    "\n",
    "    # Levenshtein\n",
    "    d = distance(a['name'], b['name'])\n",
    "\n",
    "    if d > 2:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "\n",
    "empty_row = pd.DataFrame([['nothing', -1, 0, 0, 0, 0, 0, 0, 0, -1]])\n",
    "empty_row.columns = ['name', 'polarity', 'cov_simp', 'cov_src', 'precision', 'inv_precision', 'total_coverage', 'distance', 'norm_dist', 'decision']\n",
    "\n",
    "for index, row in df_md.iterrows():\n",
    "    if index == 0:\n",
    "        prev = empty_row.iloc[0]\n",
    "    else:\n",
    "        prev = df_md.iloc[index-1]\n",
    "    \n",
    "    curr = row\n",
    "\n",
    "    if index == len(df_md) - 1:\n",
    "        next = empty_row.iloc[0]\n",
    "    else:\n",
    "        next = df_md.iloc[index+1]\n",
    "\n",
    "    if curr['precision'] > 0.5 and curr['norm_dist'] > 0.1:\n",
    "        if are_names_similar(prev, curr) and not are_names_similar(next, curr) and (curr['precision'] > prev['precision'] or curr['norm_dist'] > prev['norm_dist']):\n",
    "            thresholds.append('NEW')\n",
    "        else:\n",
    "            if are_names_similar(next, curr) and not are_names_similar(prev, curr) and (curr['precision'] > next['precision'] or curr['norm_dist'] > next['norm_dist']):\n",
    "                thresholds.append('NEW')\n",
    "            else:\n",
    "                thresholds.append('IGNORE')\n",
    "    else:\n",
    "        thresholds.append('IGNORE')\n",
    "\n",
    "df_md['new_thresholds'] = thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_md.to_excel(\"/workspace/datasets/merged_label_data.xlsx\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
